{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlgoHouse Data Quality Benchmark\n",
    "\n",
    "Comprehensive data quality analysis for crypto exchanges - detect wash trading, validate order books, and score data reliability.\n",
    "\n",
    "**Runtime:** < 10 minutes for any quant to clone and execute\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Setup\n",
    "\n",
    "Install required dependencies and configure exchange list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q ccxt pandas scipy statsmodels plotly numpy requests\n",
    "\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chisquare\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Exchanges to test (10 major exchanges)\n",
    "EXCHANGES_TO_TEST = [\n",
    "    'binance', 'kraken', 'coinbase', 'bybit', 'kucoin',\n",
    "    'gate', 'okx', 'huobi', 'mexc', 'bitget'\n",
    "]\n",
    "\n",
    "SYMBOL = 'BTC/USDT'\n",
    "SAMPLE_SIZE = 1000  # trades per exchange\n",
    "\n",
    "print(f\"‚úÖ Setup complete! Testing {len(EXCHANGES_TO_TEST)} exchanges for {SYMBOL}\")\n",
    "print(f\"üìä Data points per exchange: {SAMPLE_SIZE} trades + order book + 24h OHLCV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Data Collection\n",
    "\n",
    "Fetch data from:\n",
    "1. **CCXT**: 1000 recent trades, L2 order book (20 levels), 24h OHLCV\n",
    "2. **AlgoHouse API**: Exchange quality scores\n",
    "3. **Coin Metrics Community API**: Reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_exchange_data(exchange_id):\n",
    "    \"\"\"Fetch all required data for a single exchange.\"\"\"\n",
    "    try:\n",
    "        # Initialize exchange\n",
    "        exchange_class = getattr(ccxt, exchange_id)\n",
    "        exchange = exchange_class({\n",
    "            'enableRateLimit': True,\n",
    "            'timeout': 30000\n",
    "        })\n",
    "        \n",
    "        data = {\n",
    "            'exchange': exchange_id,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'symbol': SYMBOL\n",
    "        }\n",
    "        \n",
    "        # 1. Fetch recent trades\n",
    "        print(f\"  Fetching trades for {exchange_id}...\", end=' ')\n",
    "        trades = exchange.fetch_trades(SYMBOL, limit=SAMPLE_SIZE)\n",
    "        data['trades'] = trades\n",
    "        data['trade_count'] = len(trades)\n",
    "        print(f\"‚úì {len(trades)} trades\")\n",
    "        \n",
    "        # 2. Fetch L2 order book (20 levels)\n",
    "        print(f\"  Fetching order book for {exchange_id}...\", end=' ')\n",
    "        orderbook = exchange.fetch_order_book(SYMBOL, limit=20)\n",
    "        data['orderbook'] = orderbook\n",
    "        data['bid_levels'] = len(orderbook['bids'])\n",
    "        data['ask_levels'] = len(orderbook['asks'])\n",
    "        print(f\"‚úì {len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks\")\n",
    "        \n",
    "        # 3. Fetch 24h OHLCV\n",
    "        print(f\"  Fetching 24h OHLCV for {exchange_id}...\", end=' ')\n",
    "        since = exchange.milliseconds() - 24 * 60 * 60 * 1000\n",
    "        ohlcv = exchange.fetch_ohlcv(SYMBOL, '1h', since=since, limit=24)\n",
    "        data['ohlcv'] = ohlcv\n",
    "        data['ohlcv_count'] = len(ohlcv)\n",
    "        print(f\"‚úì {len(ohlcv)} candles\")\n",
    "        \n",
    "        # 4. Calculate 24h volume\n",
    "        ticker = exchange.fetch_ticker(SYMBOL)\n",
    "        data['volume_24h'] = ticker.get('quoteVolume', 0)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error: {str(e)[:100]}\")\n",
    "        return {\n",
    "            'exchange': exchange_id,\n",
    "            'error': str(e),\n",
    "            'trades': [],\n",
    "            'trade_count': 0\n",
    "        }\n",
    "\n",
    "# Fetch data from all exchanges\n",
    "print(\"\\nüîÑ Fetching data from all exchanges...\\n\")\n",
    "exchange_data = {}\n",
    "for exchange_id in EXCHANGES_TO_TEST:\n",
    "    print(f\"üì° {exchange_id.upper()}\")\n",
    "    exchange_data[exchange_id] = fetch_exchange_data(exchange_id)\n",
    "    time.sleep(1)  # Rate limiting\n",
    "\n",
    "print(f\"\\n‚úÖ Data collection complete! {len([e for e in exchange_data.values() if e.get('trade_count', 0) > 0])}/{len(EXCHANGES_TO_TEST)} exchanges successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch AlgoHouse quality scores\n",
    "def fetch_algohouse_scores():\n",
    "    \"\"\"Fetch exchange quality scores from AlgoHouse API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get('https://api.algohouse.com/v1/exchanges', timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return {e['id']: e for e in response.json()}\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  AlgoHouse API returned {response.status_code}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  AlgoHouse API error: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "print(\"\\nüìä Fetching AlgoHouse quality scores...\")\n",
    "algohouse_scores = fetch_algohouse_scores()\n",
    "print(f\"‚úÖ Retrieved scores for {len(algohouse_scores)} exchanges\")\n",
    "\n",
    "# Fetch Coin Metrics data (Community API - free tier)\n",
    "def fetch_coinmetrics_data():\n",
    "    \"\"\"Fetch reference data from Coin Metrics Community API.\"\"\"\n",
    "    try:\n",
    "        # Coin Metrics Community API endpoint for markets\n",
    "        url = 'https://community-api.coinmetrics.io/v4/catalog-all/markets'\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get('data', [])\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Coin Metrics API returned {response.status_code}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Coin Metrics API error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "print(\"\\nüìä Fetching Coin Metrics reference data...\")\n",
    "coinmetrics_data = fetch_coinmetrics_data()\n",
    "print(f\"‚úÖ Retrieved {len(coinmetrics_data)} markets from Coin Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Five Quality Measurements\n",
    "\n",
    "### 3.1 Tick Completeness\n",
    "Measure: % of expected trades present (no gaps > 1 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_tick_completeness(trades):\n",
    "    \"\"\"Measure tick completeness - flag gaps > 1 second.\"\"\"\n",
    "    if len(trades) < 2:\n",
    "        return {'score': 0, 'gaps': 0, 'max_gap_seconds': 0}\n",
    "    \n",
    "    # Calculate time gaps between consecutive trades\n",
    "    timestamps = [t['timestamp'] for t in trades]\n",
    "    gaps = np.diff(timestamps) / 1000  # Convert to seconds\n",
    "    \n",
    "    # Count gaps > 1 second\n",
    "    large_gaps = np.sum(gaps > 1.0)\n",
    "    max_gap = np.max(gaps)\n",
    "    \n",
    "    # Score: 100 if no large gaps, penalize 5 points per gap\n",
    "    score = max(0, 100 - (large_gaps * 5))\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'gaps_over_1s': int(large_gaps),\n",
    "        'max_gap_seconds': float(max_gap),\n",
    "        'avg_gap_ms': float(np.mean(gaps) * 1000)\n",
    "    }\n",
    "\n",
    "# Measure tick completeness for all exchanges\n",
    "tick_results = {}\n",
    "for exchange_id, data in exchange_data.items():\n",
    "    if data.get('trades'):\n",
    "        tick_results[exchange_id] = measure_tick_completeness(data['trades'])\n",
    "\n",
    "print(\"\\nüìè Tick Completeness Scores:\\n\")\n",
    "for exchange, result in sorted(tick_results.items(), key=lambda x: x[1]['score'], reverse=True):\n",
    "    print(f\"{exchange:12} Score: {result['score']:3.0f}/100  |  Gaps>1s: {result['gaps_over_1s']:3}  |  Max gap: {result['max_gap_seconds']:6.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Order Book Depth Accuracy\n",
    "Measure: Bid-ask spread reasonableness + depth at 0.1% price levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_orderbook_accuracy(orderbook, recent_price):\n",
    "    \"\"\"Measure order book depth accuracy.\"\"\"\n",
    "    if not orderbook.get('bids') or not orderbook.get('asks'):\n",
    "        return {'score': 0, 'spread_bps': 0, 'depth_quality': 'POOR'}\n",
    "    \n",
    "    bids = orderbook['bids']\n",
    "    asks = orderbook['asks']\n",
    "    \n",
    "    # Best bid/ask\n",
    "    best_bid = bids[0][0] if len(bids) > 0 else 0\n",
    "    best_ask = asks[0][0] if len(asks) > 0 else 0\n",
    "    \n",
    "    if best_bid == 0 or best_ask == 0:\n",
    "        return {'score': 0, 'spread_bps': 0, 'depth_quality': 'POOR'}\n",
    "    \n",
    "    # Spread in basis points\n",
    "    spread_bps = ((best_ask - best_bid) / best_bid) * 10000\n",
    "    \n",
    "    # Depth at 0.1% from mid (institutional standard)\n",
    "    mid_price = (best_bid + best_ask) / 2\n",
    "    target_bid = mid_price * 0.999  # -0.1%\n",
    "    target_ask = mid_price * 1.001  # +0.1%\n",
    "    \n",
    "    bid_depth = sum(level[1] for level in bids if level[0] >= target_bid)\n",
    "    ask_depth = sum(level[1] for level in asks if level[0] <= target_ask)\n",
    "    total_depth = bid_depth + ask_depth\n",
    "    \n",
    "    # Score components\n",
    "    spread_score = max(0, 100 - (spread_bps * 10))  # Penalize wide spreads\n",
    "    depth_score = min(100, total_depth * 10)  # Reward deep books\n",
    "    \n",
    "    # Combined score\n",
    "    score = (spread_score * 0.6) + (depth_score * 0.4)\n",
    "    \n",
    "    # Quality label\n",
    "    if score >= 80:\n",
    "        quality = 'EXCELLENT'\n",
    "    elif score >= 60:\n",
    "        quality = 'GOOD'\n",
    "    elif score >= 40:\n",
    "        quality = 'FAIR'\n",
    "    else:\n",
    "        quality = 'POOR'\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'spread_bps': spread_bps,\n",
    "        'bid_depth': bid_depth,\n",
    "        'ask_depth': ask_depth,\n",
    "        'depth_quality': quality\n",
    "    }\n",
    "\n",
    "# Measure order book accuracy\n",
    "orderbook_results = {}\n",
    "for exchange_id, data in exchange_data.items():\n",
    "    if data.get('orderbook') and data.get('trades'):\n",
    "        recent_price = data['trades'][-1]['price'] if data['trades'] else 0\n",
    "        orderbook_results[exchange_id] = measure_orderbook_accuracy(data['orderbook'], recent_price)\n",
    "\n",
    "print(\"\\nüìñ Order Book Depth Accuracy:\\n\")\n",
    "for exchange, result in sorted(orderbook_results.items(), key=lambda x: x[1]['score'], reverse=True):\n",
    "    print(f\"{exchange:12} Score: {result['score']:6.2f}/100  |  Spread: {result['spread_bps']:6.2f} bps  |  Quality: {result['depth_quality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Benford's Law Wash Trading Test\n",
    "\n",
    "**Academic Source:**  \n",
    "Benford's Law states that in naturally occurring datasets, the first digit follows a logarithmic distribution.  \n",
    "Wash trading (artificial volume) violates this distribution.\n",
    "\n",
    "**References:**\n",
    "- Nigrini, M. (1999). \"I've Got Your Number.\" *Journal of Accountancy*\n",
    "- Cong et al. (2022). \"Crypto Wash Trading.\" *Yale/NBER Working Paper*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benford_law_test(trades):\n",
    "    \"\"\"\n",
    "    Test trade volumes against Benford's Law distribution.\n",
    "    \n",
    "    Benford's Law: P(first_digit = d) = log10(1 + 1/d)\n",
    "    Expected distribution: [30.1%, 17.6%, 12.5%, 9.7%, 7.9%, 6.7%, 5.8%, 5.1%, 4.6%]\n",
    "    \n",
    "    Chi-squared test: H0 = trades follow Benford's Law (natural)\n",
    "    If p-value < 0.05: REJECT H0 ‚Üí likely wash trading\n",
    "    \"\"\"\n",
    "    if len(trades) < 100:\n",
    "        return {'result': 'INSUFFICIENT_DATA', 'p_value': 0, 'chi_squared': 0}\n",
    "    \n",
    "    # Extract first digit from trade amounts (volume * price)\n",
    "    amounts = [t['amount'] * t['price'] for t in trades if t.get('amount') and t.get('price')]\n",
    "    first_digits = [int(str(abs(a))[0]) for a in amounts if abs(a) >= 1]\n",
    "    \n",
    "    if len(first_digits) < 100:\n",
    "        return {'result': 'INSUFFICIENT_DATA', 'p_value': 0, 'chi_squared': 0}\n",
    "    \n",
    "    # Observed distribution\n",
    "    observed = np.bincount(first_digits, minlength=10)[1:]  # Exclude 0\n",
    "    \n",
    "    # Expected distribution (Benford's Law)\n",
    "    expected = np.array([np.log10(1 + 1/d) for d in range(1, 10)]) * len(first_digits)\n",
    "    \n",
    "    # Chi-squared test\n",
    "    chi_stat, p_value = chisquare(observed, expected)\n",
    "    \n",
    "    # Result interpretation\n",
    "    if p_value < 0.01:  # Strong evidence of manipulation\n",
    "        result = 'FAIL'\n",
    "        manipulation = 'HIGH'\n",
    "    elif p_value < 0.05:  # Moderate evidence\n",
    "        result = 'SUSPICIOUS'\n",
    "        manipulation = 'MEDIUM'\n",
    "    else:  # Follows Benford's Law (natural)\n",
    "        result = 'PASS'\n",
    "        manipulation = 'LOW'\n",
    "    \n",
    "    return {\n",
    "        'result': result,\n",
    "        'manipulation_risk': manipulation,\n",
    "        'chi_squared': float(chi_stat),\n",
    "        'p_value': float(p_value),\n",
    "        'observed_dist': observed.tolist(),\n",
    "        'expected_dist': expected.tolist()\n",
    "    }\n",
    "\n",
    "# Run Benford's Law test\n",
    "benford_results = {}\n",
    "for exchange_id, data in exchange_data.items():\n",
    "    if data.get('trades'):\n",
    "        benford_results[exchange_id] = benford_law_test(data['trades'])\n",
    "\n",
    "print(\"\\nüî¨ Benford's Law Wash Trading Test:\\n\")\n",
    "for exchange, result in sorted(benford_results.items(), key=lambda x: x[1].get('p_value', 0), reverse=True):\n",
    "    print(f\"{exchange:12} Result: {result['result']:15}  |  p-value: {result.get('p_value', 0):6.4f}  |  Risk: {result.get('manipulation_risk', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Buy/Sell Symmetry\n",
    "Measure: Flag exchanges with 49-51% buy/sell imbalance (natural is ~50/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_buy_sell_symmetry(trades):\n",
    "    \"\"\"Measure buy/sell ratio - natural markets are ~50/50.\"\"\"\n",
    "    if len(trades) < 100:\n",
    "        return {'result': 'INSUFFICIENT_DATA', 'buy_pct': 0, 'sell_pct': 0}\n",
    "    \n",
    "    # Infer side from price movement (if not explicitly provided)\n",
    "    buy_count = 0\n",
    "    sell_count = 0\n",
    "    \n",
    "    for i, trade in enumerate(trades):\n",
    "        # If side is explicitly provided\n",
    "        if 'side' in trade:\n",
    "            if trade['side'] == 'buy':\n",
    "                buy_count += 1\n",
    "            else:\n",
    "                sell_count += 1\n",
    "        # Infer from price movement\n",
    "        elif i > 0:\n",
    "            if trade['price'] > trades[i-1]['price']:\n",
    "                buy_count += 1\n",
    "            else:\n",
    "                sell_count += 1\n",
    "    \n",
    "    total = buy_count + sell_count\n",
    "    if total == 0:\n",
    "        return {'result': 'NO_DATA', 'buy_pct': 0, 'sell_pct': 0}\n",
    "    \n",
    "    buy_pct = (buy_count / total) * 100\n",
    "    sell_pct = (sell_count / total) * 100\n",
    "    \n",
    "    # Natural markets have 45-55% buy ratio\n",
    "    if 45 <= buy_pct <= 55:\n",
    "        result = 'PASS'\n",
    "    elif 40 <= buy_pct <= 60:\n",
    "        result = 'ACCEPTABLE'\n",
    "    else:\n",
    "        result = 'SUSPICIOUS'\n",
    "    \n",
    "    return {\n",
    "        'result': result,\n",
    "        'buy_pct': buy_pct,\n",
    "        'sell_pct': sell_pct,\n",
    "        'buy_count': buy_count,\n",
    "        'sell_count': sell_count\n",
    "    }\n",
    "\n",
    "# Measure buy/sell symmetry\n",
    "symmetry_results = {}\n",
    "for exchange_id, data in exchange_data.items():\n",
    "    if data.get('trades'):\n",
    "        symmetry_results[exchange_id] = measure_buy_sell_symmetry(data['trades'])\n",
    "\n",
    "print(\"\\n‚öñÔ∏è  Buy/Sell Symmetry:\\n\")\n",
    "for exchange, result in sorted(symmetry_results.items(), key=lambda x: abs(x[1].get('buy_pct', 50) - 50)):\n",
    "    print(f\"{exchange:12} Result: {result['result']:12}  |  Buy: {result.get('buy_pct', 0):5.2f}%  |  Sell: {result.get('sell_pct', 0):5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Normalization Consistency\n",
    "Measure: Timestamp alignment (all trades within 100ms bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_normalization_consistency(trades):\n",
    "    \"\"\"Measure timestamp normalization quality - should align to 100ms bins.\"\"\"\n",
    "    if len(trades) < 100:\n",
    "        return {'score': 0, 'consistency': 'POOR'}\n",
    "    \n",
    "    # Check timestamp precision\n",
    "    timestamps = [t['timestamp'] for t in trades]\n",
    "    \n",
    "    # Count how many timestamps align to 100ms boundaries\n",
    "    aligned_count = sum(1 for ts in timestamps if ts % 100 == 0)\n",
    "    alignment_pct = (aligned_count / len(timestamps)) * 100\n",
    "    \n",
    "    # Check for duplicate timestamps (indicates poor precision)\n",
    "    unique_ts = len(set(timestamps))\n",
    "    uniqueness_pct = (unique_ts / len(timestamps)) * 100\n",
    "    \n",
    "    # Score: penalize low uniqueness and poor alignment\n",
    "    score = (uniqueness_pct * 0.7) + (min(alignment_pct, 50) * 0.6)  # Don't over-reward alignment\n",
    "    \n",
    "    if score >= 80:\n",
    "        consistency = 'EXCELLENT'\n",
    "    elif score >= 60:\n",
    "        consistency = 'GOOD'\n",
    "    elif score >= 40:\n",
    "        consistency = 'FAIR'\n",
    "    else:\n",
    "        consistency = 'POOR'\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'consistency': consistency,\n",
    "        'uniqueness_pct': uniqueness_pct,\n",
    "        'alignment_pct': alignment_pct\n",
    "    }\n",
    "\n",
    "# Measure normalization consistency\n",
    "normalization_results = {}\n",
    "for exchange_id, data in exchange_data.items():\n",
    "    if data.get('trades'):\n",
    "        normalization_results[exchange_id] = measure_normalization_consistency(data['trades'])\n",
    "\n",
    "print(\"\\nüïê Timestamp Normalization Consistency:\\n\")\n",
    "for exchange, result in sorted(normalization_results.items(), key=lambda x: x[1]['score'], reverse=True):\n",
    "    print(f\"{exchange:12} Score: {result['score']:6.2f}/100  |  Uniqueness: {result['uniqueness_pct']:5.2f}%  |  Quality: {result['consistency']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Composite Data Trust Score\n",
    "\n",
    "Calculate overall data quality score (0-100) for each exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trust_score(exchange_id):\n",
    "    \"\"\"\n",
    "    Calculate composite Data Trust Score (0-100) from all measurements.\n",
    "    \n",
    "    Weights:\n",
    "    - Benford's Law: 30% (wash trading is the biggest risk)\n",
    "    - Order Book Accuracy: 25% (critical for execution)\n",
    "    - Tick Completeness: 20% (data gaps corrupt backtests)\n",
    "    - Buy/Sell Symmetry: 15% (market balance)\n",
    "    - Normalization: 10% (timestamp quality)\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Benford's Law (30%)\n",
    "    if exchange_id in benford_results:\n",
    "        benford = benford_results[exchange_id]\n",
    "        if benford['result'] == 'PASS':\n",
    "            scores['benford'] = 100\n",
    "        elif benford['result'] == 'SUSPICIOUS':\n",
    "            scores['benford'] = 50\n",
    "        elif benford['result'] == 'FAIL':\n",
    "            scores['benford'] = 0\n",
    "        else:\n",
    "            scores['benford'] = 50\n",
    "    else:\n",
    "        scores['benford'] = 50\n",
    "    \n",
    "    # Order Book Accuracy (25%)\n",
    "    if exchange_id in orderbook_results:\n",
    "        scores['orderbook'] = orderbook_results[exchange_id]['score']\n",
    "    else:\n",
    "        scores['orderbook'] = 0\n",
    "    \n",
    "    # Tick Completeness (20%)\n",
    "    if exchange_id in tick_results:\n",
    "        scores['tick'] = tick_results[exchange_id]['score']\n",
    "    else:\n",
    "        scores['tick'] = 0\n",
    "    \n",
    "    # Buy/Sell Symmetry (15%)\n",
    "    if exchange_id in symmetry_results:\n",
    "        symmetry = symmetry_results[exchange_id]\n",
    "        if symmetry['result'] == 'PASS':\n",
    "            scores['symmetry'] = 100\n",
    "        elif symmetry['result'] == 'ACCEPTABLE':\n",
    "            scores['symmetry'] = 70\n",
    "        else:\n",
    "            scores['symmetry'] = 30\n",
    "    else:\n",
    "        scores['symmetry'] = 50\n",
    "    \n",
    "    # Normalization (10%)\n",
    "    if exchange_id in normalization_results:\n",
    "        scores['normalization'] = normalization_results[exchange_id]['score']\n",
    "    else:\n",
    "        scores['normalization'] = 0\n",
    "    \n",
    "    # Weighted composite score\n",
    "    trust_score = (\n",
    "        scores['benford'] * 0.30 +\n",
    "        scores['orderbook'] * 0.25 +\n",
    "        scores['tick'] * 0.20 +\n",
    "        scores['symmetry'] * 0.15 +\n",
    "        scores['normalization'] * 0.10\n",
    "    )\n",
    "    \n",
    "    # Grade\n",
    "    if trust_score >= 90:\n",
    "        grade = 'A+'\n",
    "    elif trust_score >= 80:\n",
    "        grade = 'A'\n",
    "    elif trust_score >= 70:\n",
    "        grade = 'B'\n",
    "    elif trust_score >= 60:\n",
    "        grade = 'C'\n",
    "    elif trust_score >= 50:\n",
    "        grade = 'D'\n",
    "    else:\n",
    "        grade = 'F'\n",
    "    \n",
    "    return {\n",
    "        'trust_score': trust_score,\n",
    "        'grade': grade,\n",
    "        'component_scores': scores\n",
    "    }\n",
    "\n",
    "# Calculate trust scores for all exchanges\n",
    "trust_scores = {}\n",
    "for exchange_id in EXCHANGES_TO_TEST:\n",
    "    trust_scores[exchange_id] = calculate_trust_score(exchange_id)\n",
    "\n",
    "print(\"\\nüèÜ Composite Data Trust Scores:\\n\")\n",
    "print(f\"{'Exchange':<12} {'Score':>8} {'Grade':>6} {'Benford':>8} {'OB':>8} {'Tick':>8} {'Sym':>8} {'Norm':>8}\")\n",
    "print(\"=\" * 80)\n",
    "for exchange, data in sorted(trust_scores.items(), key=lambda x: x[1]['trust_score'], reverse=True):\n",
    "    cs = data['component_scores']\n",
    "    print(f\"{exchange:<12} {data['trust_score']:>8.1f} {data['grade']:>6} {cs['benford']:>8.0f} {cs['orderbook']:>8.0f} {cs['tick']:>8.0f} {cs['symmetry']:>8.0f} {cs['normalization']:>8.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Visualizations\n",
    "\n",
    "Interactive Plotly charts (dark mode) for data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Trust Score Heatmap\n",
    "def create_trust_score_heatmap():\n",
    "    \"\"\"Create heatmap of all quality metrics.\"\"\"\n",
    "    exchanges = list(trust_scores.keys())\n",
    "    metrics = ['Benford', 'Order Book', 'Tick Complete', 'Buy/Sell Sym', 'Normalization']\n",
    "    \n",
    "    # Build matrix\n",
    "    matrix = []\n",
    "    for exchange in exchanges:\n",
    "        cs = trust_scores[exchange]['component_scores']\n",
    "        matrix.append([\n",
    "            cs['benford'],\n",
    "            cs['orderbook'],\n",
    "            cs['tick'],\n",
    "            cs['symmetry'],\n",
    "            cs['normalization']\n",
    "        ])\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=matrix,\n",
    "        x=metrics,\n",
    "        y=exchanges,\n",
    "        colorscale='RdYlGn',\n",
    "        text=matrix,\n",
    "        texttemplate='%{text:.0f}',\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title=\"Score\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Exchange Data Quality Heatmap (0-100 Scale)',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        xaxis_title='Quality Metric',\n",
    "        yaxis_title='Exchange'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "heatmap_fig = create_trust_score_heatmap()\n",
    "heatmap_fig.show()\n",
    "heatmap_fig.write_html('/home/ubuntu/.openclaw/workspace/algohouse-data-quality-benchmark/heatmap.html')\n",
    "print(\"\\n‚úÖ Heatmap saved to heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Trust Score vs. Volume Scatter Plot\n",
    "def create_trust_vs_volume_scatter():\n",
    "    \"\"\"Scatter plot: Trust Score vs. 24h Volume.\"\"\"\n",
    "    exchanges_list = []\n",
    "    trust_list = []\n",
    "    volume_list = []\n",
    "    \n",
    "    for exchange in EXCHANGES_TO_TEST:\n",
    "        if exchange in trust_scores and exchange in exchange_data:\n",
    "            exchanges_list.append(exchange.upper())\n",
    "            trust_list.append(trust_scores[exchange]['trust_score'])\n",
    "            volume_list.append(exchange_data[exchange].get('volume_24h', 0))\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x=volume_list,\n",
    "        y=trust_list,\n",
    "        mode='markers+text',\n",
    "        text=exchanges_list,\n",
    "        textposition='top center',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color=trust_list,\n",
    "            colorscale='RdYlGn',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Trust Score\")\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Data Trust Score vs. 24h Volume',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        xaxis_title='24h Volume (USDT)',\n",
    "        yaxis_title='Data Trust Score (0-100)',\n",
    "        xaxis_type='log'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "scatter_fig = create_trust_vs_volume_scatter()\n",
    "scatter_fig.show()\n",
    "scatter_fig.write_html('/home/ubuntu/.openclaw/workspace/algohouse-data-quality-benchmark/scatter.html')\n",
    "print(\"\\n‚úÖ Scatter plot saved to scatter.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Trust Score Bar Chart (Ranked)\n",
    "def create_trust_score_bar_chart():\n",
    "    \"\"\"Bar chart of trust scores ranked high to low.\"\"\"\n",
    "    sorted_exchanges = sorted(trust_scores.items(), key=lambda x: x[1]['trust_score'], reverse=True)\n",
    "    \n",
    "    exchanges = [e[0].upper() for e in sorted_exchanges]\n",
    "    scores = [e[1]['trust_score'] for e in sorted_exchanges]\n",
    "    grades = [e[1]['grade'] for e in sorted_exchanges]\n",
    "    \n",
    "    colors = ['#00cc66' if s >= 80 else '#ffcc00' if s >= 60 else '#ff6666' for s in scores]\n",
    "    \n",
    "    fig = go.Figure(data=go.Bar(\n",
    "        x=exchanges,\n",
    "        y=scores,\n",
    "        text=[f\"{s:.1f} ({g})\" for s, g in zip(scores, grades)],\n",
    "        textposition='outside',\n",
    "        marker_color=colors\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Exchange Data Trust Scores (Ranked)',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        xaxis_title='Exchange',\n",
    "        yaxis_title='Trust Score (0-100)',\n",
    "        yaxis_range=[0, 110]\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "bar_fig = create_trust_score_bar_chart()\n",
    "bar_fig.show()\n",
    "bar_fig.write_html('/home/ubuntu/.openclaw/workspace/algohouse-data-quality-benchmark/barchart.html')\n",
    "print(\"\\n‚úÖ Bar chart saved to barchart.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä ALGOHOUSE DATA QUALITY BENCHMARK - SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÖ Benchmark Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üéØ Symbol Tested: {SYMBOL}\")\n",
    "print(f\"üî¢ Exchanges Tested: {len(EXCHANGES_TO_TEST)}\")\n",
    "print(f\"üìà Trades Analyzed: {sum(d.get('trade_count', 0) for d in exchange_data.values())}\")\n",
    "\n",
    "print(\"\\nüèÜ TOP 3 EXCHANGES BY TRUST SCORE:\")\n",
    "top_3 = sorted(trust_scores.items(), key=lambda x: x[1]['trust_score'], reverse=True)[:3]\n",
    "for rank, (exchange, data) in enumerate(top_3, 1):\n",
    "    print(f\"  {rank}. {exchange.upper():12} - Score: {data['trust_score']:.1f}/100 (Grade: {data['grade']})\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  EXCHANGES FLAGGED FOR WASH TRADING (Benford's Law):\")\n",
    "flagged = [e for e, r in benford_results.items() if r['result'] in ['FAIL', 'SUSPICIOUS']]\n",
    "if flagged:\n",
    "    for exchange in flagged:\n",
    "        result = benford_results[exchange]\n",
    "        print(f\"  - {exchange.upper():12} ({result['result']}, p-value: {result.get('p_value', 0):.4f})\")\n",
    "else:\n",
    "    print(\"  ‚úÖ No exchanges flagged\")\n",
    "\n",
    "print(\"\\nüìä EXPORTS:\")\n",
    "print(\"  - heatmap.html (quality metrics heatmap)\")\n",
    "print(\"  - scatter.html (trust vs. volume)\")\n",
    "print(\"  - barchart.html (ranked trust scores)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Benchmark complete! Runtime: < 10 minutes\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
